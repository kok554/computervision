{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPTqH9+Z2ooJras5FNrCVUI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kok554/computervision/blob/main/study.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fWJNYdMO1Dz9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 텐서 초기화\n",
        "data = [[1,2], [3,4]]\n",
        "x_data = torch.tensor(data)"
      ],
      "metadata": {
        "id": "RC33lYR61xt7"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Numpy 배열로 Tensor 생성하기\n",
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ],
      "metadata": {
        "id": "3RxXVLa_1F_h"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shape = (2,3, )\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor}\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor}\")\n",
        "print(f\"Zeros_Tensor: \\n {zeros_tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXA3Aien1F9O",
        "outputId": "edb450af-7809-46c4-93cd-fd6b499e3720"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.2777, 0.0029, 0.8740],\n",
            "        [0.2569, 0.2697, 0.3602]])\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "Zeros_Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch를 사용하여 FashionMNIST 데이터셋을 로드하기 위한 라이브러리 import\n",
        "import torch\n",
        "from torchvision import datasets # torchvision을 통해 데이터셋을 쉽게 가져올수있음\n",
        "from torchvision.transforms import ToTensor # 데이터셋 이미지를 Tensor로 변환\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# FashionMNIST 데이터셋의 학습 데이터 로드\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root = \"data\", # 데이터를 저장할 디렉터리 경로\n",
        "    train = True, # 학습용 데이터셋 로드\n",
        "    download = True, # 데이터가 없으면 다운로드\n",
        "    transform = ToTensor() #이미지를 ToTensor 형태로 변환\n",
        ")\n",
        "\n",
        "# FashionMNIST 데이터셋의 테스트 데이터 로드\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root = \"data\",\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = ToTensor()\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHAvtxs41F6-",
        "outputId": "e7073359-303c-4078-ae2d-924cbb382901"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 14.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 210kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.93MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 6.08MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 레이블 매핑 정의\n",
        "labels_map = {\n",
        "0: \"T-Shirt\",\n",
        "1: \"Trouser\",\n",
        "2: \"Pullover\",\n",
        "3: \"Dress\",\n",
        "4: \"Coat\",\n",
        "5: \"Sandal\",\n",
        "6: \"Shirt\",\n",
        "7: \"Sneaker\",\n",
        "8: \"Bag\",\n",
        "9: \"Ankle Boot\",\n",
        "}"
      ],
      "metadata": {
        "id": "OqRfHqJL1F4i"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "wI7HTjNP4_r-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 열과 행 개수를 정의\n",
        "cols, rows = 3,3\n",
        "\n",
        "# 이미지를 저장할 빈 리스트 생성\n",
        "images = []\n",
        "\n",
        "# 3x3 = 9개의 이미지를 가져오기 위한 반복문\n",
        "for i in range(cols * rows):\n",
        "  # training_data에서 랜덤한 인덱스를 선택\n",
        "  sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "  # 랜덤 인덱스에 해당하는 이미지와 레이블 가져오기\n",
        "  img, label = training_data[sample_idx]\n",
        "  # 이미지 텐스를 2차원 형태로 압축 (채널 제거)하고 Numpy 배열로 변환\n",
        "  img = img.squeeze().numpy()\n",
        "  # OpenCv를 사용해 흑백 이미지를 BGR 이미지로 변환\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)\n",
        "  # 이미지를 100x100 픽셀로 크기 조정\n",
        "  img = cv2.resize(img, (100, 100))\n",
        "  # 레이블 맵에서 현재 레이블에 해당하는 텍스트를 가져옴\n",
        "  title = labels_map[label]\n",
        "  # 이미지 위에 텍스트로 레이블을 추가\n",
        "  img = cv2.putText(\n",
        "        img,                  # 이미지\n",
        "        title,                # 텍스트 (레이블 이름)\n",
        "        (5, 15),              # 텍스트 시작 위치 (x, y 좌표)\n",
        "        cv2.FONT_HERSHEY_SIMPLEX,  # 폰트 종류\n",
        "        0.5,                  # 폰트 크기\n",
        "        (255, 255, 255),      # 텍스트 색상 (흰색)\n",
        "        1,                    # 텍스트 두께\n",
        "        cv2.LINE_AA           # 텍스트 렌더링 방식 (안티에일리어싱 적용)\n",
        "    )\n",
        "  # 처리된 이미지를 리스트에 추가\n",
        "  images.append(img)\n",
        "\n",
        "# 각 행에 포함된 이미지를 수평으로 결합하여 한 행으로 만듦\n",
        "rows_images = [np.hstack(images[i*cols:(i+1)*cols]) for i in range(rows)]\n",
        "\n",
        "# 행들을 수직으로 결합하여 최종적으로 3x3 그리드 이미지를 생성\n",
        "grid_image = np.vstack(rows_images)\n",
        "\n",
        "# OpenCV 창에 이미지 그리드를 띄움\n",
        "cv2_imshow(grid_image)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "l_GvrT2y1F2A",
        "outputId": "8569a4fe-87aa-48a6-9101-f1d9c257fe1b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=300x300>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAASwAAAEsCAIAAAD2HxkiAAAKWElEQVR4Ae3Y247jOA4A0Mmg//+Xs8JoQRCirShOnM7l1ENBJkVJPLaT6v7nHz8ECBAgQIAAAQIECBAgQIAAAQJ/ReAy2fV6vebs5TKbnGdOxm3Np6zTtmjrDCec7Htqqh7jWT3mYy/SLU7LK79+fO8h9+bvxRc7auV15lPu3V0H+1MP0SPDKu1yiOwV/lq8svxH9bTPmu/zbD7v01R95eoNPfu0/25uUM9Rz7pZKNgEmhUuT8K6wO43YV2iPljxkTZJ9XX6hD6//64ldceviQRU1mjjFm8OOTuw5FTVyNmhsE5+k0hvOXqPU+V4D046islRHoMzTGLNeqRItQNEtgf77wjGCVcHeem9mpgTg5iZI208XMa0rxn0HnObubUc7zMjWy8j1QaTwpydL5IXfIdxNBWDfqp+GcEY5Ox83LK5Ko97Yf1d57TIEIzLGMQ6OZLHw0li/t7gjm/CvETbMl7xNsiXeZxLvngcFHEnciTGmwJ72TljzrYVYt/NLT4lmJtqZx4uexebwb3UZHKYtDkx7oN8R/IK3TmyObV3gGHlvcvtfxPuzZ5sVpvpk+PQ8zW/I9uanfc7z04QcmG9/ZPCt0rlk7eOhmcm95jH0UIuj2AetAnxk+OTcdto+Gkr9Plt0FJDbWSHeJ05TJhcHvwmHFZsJ9g73DDzRy4379+P9D5v8/BzslL4yJswP3bPnvSc3/ESTh6sSWqlty+bc9Kt+nSlzYdkM7jZaX/B1udvLvJg8KTdd/8cbfvtndhDlmUmUHnaE8e/7H9X7w/emrv2euT+bn8T9u2HHlow75SzOTU/es7mqrzyx40zRT98tJb7vauvm4V107vWf5/JrZHgWjlVl6klVazOqetXxqEqT8ip+XY5m6vqAUQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECDwdQLX6/XretLQ3QJ/9irq83G5XPYmH463XVaWXZx2+BgPFk6sJievVfUYk/I6+SMiteuVB+De1hbdFqfdu/tz5lepFqnBxzdbXHNx2uPnObBCPVuLRDAGB1ZuJQ+WH9v0vKraTovU4OMHWFxzcdrj55mvsPtNOJSd8XE1bPE1l6zWbyWrZrX6ElbW4VMkNFu8jXM2Un2RnJovOxTWyR8Uia5zU90qWAa3iLdBrvqgrg8cNaB6bTTerXI2Un1mTtV9c3YorJNfHNl+Cdsp49CbJ27ZiMfMOPokO0m18sjWNWPxdxvctFrvK9qPHmskUp84uGmV+63PwCQ7Sa37/y3S7Zewnaa+YzkS481z72WzVC3M2bZCu6xz3jMS/caZI9IOnPuql7mjXJXj3zSOHqvVAFW7jtohNS/M2bZC7Dss8hcv/725dzt3+5lMm2cXC7PUpOTNU/9RjVbZJ4/fvJezj7dplTc9bJULP+K5uv0ShssbfoTE2d5twGr9jrBafQnzp8u672/OZLV+31k1q+2X8PUfTu1mvH7T9WdlMvNDjz3p6LzU660+4rna/Y+Z6hUfWocbu1lYNz3vgXjiyvXYYfX4Ln3xJy74+JEeWWFidfPx2Nv3ZmHddG8pcQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAAQIECBAgQIAAgV2By25GgsDnC1wuR57w6/X6+a3rgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIEHidwPV6fd1mH74Tqw+/gf8//p/axt6tvVwudfJepC4S5S0V46G8Vg0T2uWkvE4+O7J34L0GN89TF4nySbO1qi4+Ka+TXxOpx45mn3iAxcYXpz3xYHcvVb0Wl6iFLRLBGCyuNkx7sHxY7VmXh09VC1skgjE4ds4Hy49tOqmq52mRGpyssJhaXHNx2uKmh6dtfBMeXmtSeMan3WS7j079lNVPNbv3WL7oJdzcPj6H8p1owbjs45gWi/RITIv4Fw8CIXfdfXrXfRzTgqJHclWk3nMwtBAnrw1GKgQmHeVlh8JJ1WtSp7yErcnoea/hbtqajJmbDce0yNZIpD5x8FNWN5vNN7c+GJPsJNWeisjWNd/hmTnlJWyNxbsXbUcko3SCMKoiuapmvyMSPf6C1aTZyWPQb3TUDvd9XpizbYVAHhb5i5f3vYTzBjaNenAozDPf0+XxWzK0PCyYBSL1U1abzQZFGxx+MHJhuwt9o7zyu43vewkf6ecjOJ54e1gtYv7ag1FZ/q2hMyKPPJFnnOed1/wpq59qdu+pO+UlnP8ltneU34z/lNXrm20v+es3vfdJvu/P0fXVa+dP/Mzriz9xwfW+zpj5U1aTZg+/MDcL66Zn3EdrEiBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgAABAgQIECBAgMAbCvwPib4N/Ao7DmYAAAAASUVORK5CYII=\n",
            "image/jpeg": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 가져오기\n",
        "import os  # 파일 및 디렉터리 경로 처리를 위한 모듈\n",
        "import cv2  # OpenCV 라이브러리, 이미지 로드 및 처리에 사용\n",
        "from torch.utils.data import Dataset, DataLoader  # PyTorch 데이터셋 및 데이터 로더\n",
        "from torchvision import transforms  # 이미지 데이터 변환을 위한 torchvision 모듈\n",
        "\n",
        "# 커스텀 데이터셋 클래스 정의 (PyTorch의 Dataset 상속)\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, img_dir, transform=None):\n",
        "        \"\"\"\n",
        "        클래스 초기화 메서드. 데이터셋의 경로 및 변환 설정.\n",
        "        - img_dir: 이미지가 저장된 디렉터리 경로 (string)\n",
        "        - transform: 이미지 변환 파이프라인 (torchvision.transforms.Compose 등)\n",
        "        \"\"\"\n",
        "        self.img_dir = img_dir  # 이미지가 저장된 디렉터리 경로 저장\n",
        "        self.transform = transform  # 이미지 변환 설정 저장\n",
        "        self.img_labels = []  # 이미지 경로와 레이블 정보를 저장할 리스트 초기화\n",
        "\n",
        "        # 'cats' 디렉터리 경로 생성 및 이미지 레이블링 (레이블: 0)\n",
        "        a_dir = os.path.join(img_dir, 'cats')\n",
        "        self.img_labels += [\n",
        "            (os.path.join(a_dir, img), 0)  # 각 이미지 경로와 레이블 0 추가\n",
        "            for img in os.listdir(a_dir)  # 디렉터리 내 파일 목록 확인\n",
        "            if img.endswith(('jpg', 'png', 'jpeg'))  # 특정 확장자 필터링\n",
        "        ]\n",
        "\n",
        "        # 'dogs' 디렉터리 경로 생성 및 이미지 레이블링 (레이블: 1)\n",
        "        b_dir = os.path.join(img_dir, 'dogs')\n",
        "        self.img_labels += [\n",
        "            (os.path.join(b_dir, img), 1)  # 각 이미지 경로와 레이블 1 추가\n",
        "            for img in os.listdir(b_dir)  # 디렉터리 내 파일 목록 확인\n",
        "            if img.endswith(('jpg', 'png', 'jpeg'))  # 특정 확장자 필터링\n",
        "        ]\n",
        "\n",
        "        # 변환(transform)이 설정되지 않은 경우 기본 변환 설정\n",
        "        if self.transform is None:\n",
        "            self.transform = transforms.Compose([\n",
        "                transforms.ToPILImage(),  # OpenCV 이미지를 PIL 이미지로 변환\n",
        "                transforms.Resize((128, 128)),  # 이미지를 128x128 크기로 조정\n",
        "                transforms.ToTensor(),  # 이미지를 텐서로 변환 (범위: [0, 1])\n",
        "                # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "                # 정규화: 각 RGB 채널의 평균과 표준편차를 기준으로 정규화\n",
        "            ])\n",
        "\n",
        "    def __len__(self):\n",
        "        # 데이터셋의 전체 이미지 개수를 반환하는 메서드\n",
        "        # PyTorch DataLoader에서 데이터셋 크기를 알기 위해 호출\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        주어진 인덱스(idx)에 해당하는 데이터(이미지와 레이블)를 반환하는 메서드\n",
        "        - idx: 데이터셋에서 접근할 데이터의 인덱스\n",
        "        \"\"\"\n",
        "\n",
        "        # 인덱스를 이용해 이미지 경로와 레이블을 가져옴\n",
        "        img_path, label = self.img_labels[idx]\n",
        "\n",
        "        # OpenCV를 사용해 이미지 파일 읽기\n",
        "        image = cv2.imread(img_path)  # BGR 형식으로 이미지를 읽음\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # BGR -> RGB 변환 (PyTorch는 RGB 형식 사용)\n",
        "\n",
        "        # 이미지 변환(transform)이 설정된 경우 적용\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        # (이미지, 레이블) 튜플 반환\n",
        "        return image, label\n",
        "\n",
        "# 데이터 로더를 생성하는 함수\n",
        "def create_data_loader(img_dir, batch_size=2, shuffle=True):\n",
        "\n",
        "    # 커스텀 데이터셋 객체 생성\n",
        "    dataset = CustomImageDataset(img_dir)\n",
        "\n",
        "    # DataLoader 생성 및 반환\n",
        "    # - dataset: 데이터를 로드할 데이터셋 객체\n",
        "    # - batch_size: 지정된 크기로 데이터를 배치로 묶음\n",
        "    # - shuffle: 데이터셋의 순서를 랜덤으로 섞을지 여부\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n"
      ],
      "metadata": {
        "id": "VccgUJmK3Ihu"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import create_data_loader\n",
        "\n",
        "# 데이터 디렉터리와 배치 크기 설정\n",
        "img_dir = 'data'  # 이미지 데이터가 저장된 폴더 경로\n",
        "batch_size = 2  # 한 번에 로드할 데이터의 개수\n",
        "\n",
        "# 데이터 로더 생성\n",
        "data_loader = create_data_loader(img_dir, batch_size=batch_size)\n",
        "\n",
        "# 데이터 로더에서 데이터를 반복하여 처리\n",
        "for images, labels in data_loader:\n",
        "    # 이미지를 NumPy 배열로 변환하고 값 범위를 [0, 255]로 조정\n",
        "    # PyTorch 텐서: (Batch, Channels, Height, Width)\n",
        "    # OpenCV가 지원하는 형식: (Height, Width, Channels)\n",
        "    images = (images.permute(0, 2, 3, 1).numpy() * 255).astype('uint8')\n",
        "    # `.permute(0, 2, 3, 1)`로 차원을 재배열: (Batch, Height, Width, Channels)\n",
        "\n",
        "    # 배치의 두 이미지를 가로로 결합\n",
        "    combined_image = cv2.hconcat([images[0], images[1]])  # 두 이미지를 가로로 합침\n",
        "\n",
        "    # 이미지에 레이블 정보 추가\n",
        "    label_text = f'Label 1: {labels[0].item()}, Label 2: {labels[1].item()}'\n",
        "    cv2.putText(\n",
        "        combined_image,  # 텍스트를 추가할 이미지\n",
        "        label_text,  # 추가할 텍스트\n",
        "        (10, 20),  # 텍스트 시작 위치 (x, y 좌표)\n",
        "        cv2.FONT_HERSHEY_SIMPLEX,  # 폰트 종류\n",
        "        0.6,  # 글자 크기\n",
        "        (255, 255, 255),  # 글자 색 (흰색)\n",
        "        1  # 글자 두께\n",
        "    )\n",
        "\n",
        "    # OpenCV 창에 결합된 이미지 출력\n",
        "    cv2.imshow(\"Batch of 2 Images\", combined_image)\n",
        "\n",
        "    # 키 입력 대기: 'q' 키를 누르면 반복문 종료\n",
        "    if cv2.waitKey(0) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# 모든 OpenCV 창 닫기\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "mtLerov13Icq",
        "outputId": "0773b032-9fa4-4361-fadf-90809a18fc07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'create_data_loader'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-2db9d9c804a2>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_data_loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# 데이터 디렉터리와 배치 크기 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'data'\u001b[0m  \u001b[0;31m# 이미지 데이터가 저장된 폴더 경로\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'create_data_loader'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ucUOw6Hu3IZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2uxco3Kh1Fzn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}