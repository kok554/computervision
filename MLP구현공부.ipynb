{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMrIazBBtPpyK0MSPOFBsZd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kok554/computervision/blob/main/MLP%EA%B5%AC%ED%98%84%EA%B3%B5%EB%B6%80.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQ_5Nj-h_y09",
        "outputId": "b110a969-bf30-4ab5-d478-fb94b27ed3ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 494kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.54MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.65MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# 필요한 라이브러리 가져오기\n",
        "import torch  # PyTorch 라이브러리 (주로 텐서 연산 및 모델 학습)\n",
        "import torch.nn as nn  # 신경망 모델을 구축하기 위한 모듈\n",
        "import torch.nn.functional as F  # 신경망의 함수들 (예: 활성화 함수, 손실 함수 등)\n",
        "import torch.optim as optim  # 최적화 알고리즘을 위한 모듈\n",
        "from torchvision import datasets, transforms  # torchvision 라이브러리 (MNIST 데이터셋 및 이미지 변환)\n",
        "from torch.utils.data import DataLoader  # 데이터를 배치로 로드할 수 있는 DataLoader\n",
        "\n",
        "# 이미지 변환을 위한 변환 파이프라인 정의\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # 이미지를 PyTorch 텐서로 변환 (값 범위: [0, 1])\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # MNIST 데이터셋의 평균 및 표준편차를 기준으로 정규화\n",
        "])\n",
        "\n",
        "# MNIST 훈련 데이터셋 로드\n",
        "train_dataset = datasets.MNIST(\n",
        "    './data',  # 데이터셋을 저장할 디렉터리 경로\n",
        "    train=True,  # 훈련 데이터셋\n",
        "    download=True,  # 데이터셋이 없다면 자동으로 다운로드\n",
        "    transform=transform  # 앞에서 정의한 변환(transform)을 적용\n",
        ")\n",
        "\n",
        "# MNIST 테스트 데이터셋 로드\n",
        "test_dataset = datasets.MNIST(\n",
        "    './data',  # 데이터셋을 저장할 디렉터리 경로\n",
        "    train=False,  # 테스트 데이터셋\n",
        "    transform=transform  # 앞에서 정의한 변환(transform)을 적용\n",
        ")\n",
        "\n",
        "# 훈련 데이터셋을 배치 크기 64로 DataLoader로 로드\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,  # 훈련 데이터셋\n",
        "    batch_size=64,  # 배치 크기 (한 번에 64개의 샘플을 로드)\n",
        "    shuffle=True  # 데이터를 섞어서 로드 (매 epoch마다 데이터가 섞임)\n",
        ")\n",
        "\n",
        "# 테스트 데이터셋을 배치 크기 1000으로 DataLoader로 로드\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,  # 테스트 데이터셋\n",
        "    batch_size=1000,  # 배치 크기 (한 번에 1000개의 샘플을 로드)\n",
        "    shuffle=False  # 테스트 데이터는 순차적으로 로드 (섞지 않음)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP 클래스 정의\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    \"\"\"\n",
        "    클래스 초기화 메서드.\n",
        "    MLP 모델의 레이어들을 정의합니다.\n",
        "    \"\"\"\n",
        "    super(MLP, self).__init__() # 부모 클래스인 nn.Module의 초기화 메서드 호출\n",
        "\n",
        "    # 첫 번째 완전 연결 계층 (입력 크기: 28x28, 출력 크기: 512)\n",
        "    self.fc1 = nn.Linear(28*28, 512)\n",
        "\n",
        "    # 두 번째 완전 연결 계층 (입력 크기: 512, 출력 크기: 10)\n",
        "    self.fc2 = nn.Linear(512, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\"\n",
        "    순전파 메서드.\n",
        "    - x: 입력 데이터 (배치 크기, 28, 28 크기의 이미지 텐서)\n",
        "    \"\"\"\n",
        "\n",
        "    # 이미지는 28x28 픽셀 크기이며, 이를 1차원 벡터로 변환\n",
        "    x = x.view(-1, 28*28) # 배치 크기에 맞게 자동으로 크기 조정\n",
        "\n",
        "    # 첫 번째 완전 연결 계층을 통과\n",
        "    x = self.fc1(x)\n",
        "\n",
        "    # ReLU 활성화 함수 적용 (비선형 변환)\n",
        "    x = F.relu(x)\n",
        "\n",
        "    # 두 번째 완전 연결 계층 통과\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    # 소프트맥스 함수 적용하여 클래스 확률을 계산\n",
        "    return F.softmax(x, dim =1) # 각 클래스에 대한 확률 분포 계산"
      ],
      "metadata": {
        "id": "CzpOCWDB_4FT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MLP 모델 인스턴스 생성\n",
        "model = MLP()\n",
        "# 손실 함수로 CrossEntropyLoss 사용\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# 옵티마이저로 SGD 사용\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
      ],
      "metadata": {
        "id": "QZRApsKC_4DD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "  # 모델을 훈련 모드로 설정합니다. 훈련 시에는 드롭아웃이나 배치 정규화 등이 활성화됩니다.\n",
        "  model.train()\n",
        "\n",
        "  # train_loader에서 배치 단위로 데이터를 가져와서 학습을 진행합니다.\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    # 데이터를 지정된 장치(CPU 또는 GPU)로 이동\n",
        "    data, target = data.to(device), target.to(device)\n",
        "\n",
        "    # 이전에 계산된 그래디언트를 초기화\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 모델을 사용하여 입력 데이터를 처리\n",
        "    output = model(data)\n",
        "\n",
        "    # 모델 출력과 실제 레이블(target) 간의 손실(loss) 계산\n",
        "    loss = criterion(output, target)\n",
        "\n",
        "    # 손실에 따라 그래디언트 계산 (역전파 수행)\n",
        "    loss.backward()\n",
        "\n",
        "    # 옵티마이저를 통해 모델의 파라미터 업데이트\n",
        "    optimizer.step()\n",
        "\n",
        "    # 10번째 배치마다 학습 상태 출력\n",
        "    if batch_idx % 10 == 0:\n",
        "        print(f'Train Epoch: {epoch+1} '\n",
        "              f'[{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
        "              f'({100. * batch_idx / len(train_loader):.0f}%)]\\t'\n",
        "              f'Loss: {loss.item():.6f}')"
      ],
      "metadata": {
        "id": "up3aSa9nGZfr"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, device, test_loader):\n",
        "  # 모델을 평가 모드로 설정 (드롭아웃 및 배치 정규화 비활성화)\n",
        "  model.eval()\n",
        "\n",
        "  # 테스트 손실 누적 값 초기화\n",
        "  test_loss = 0\n",
        "  # 테스트 데이터 중 정답을 맞춘 개수를 세기 위한 변수 초기화\n",
        "  correct = 0\n",
        "\n",
        "  # 평가 모드에서는 그래디언트를 계산하지 않음\n",
        "  with torch.no_grad():\n",
        "    # 테스트 데이터 로더에서 배치를 하나씩 가져오기\n",
        "    for data, target in test_loader:\n",
        "      # 데이터를 지정된 장치(CPU 또는 GPU)로 이동\n",
        "      data, target = data.to(device), target.to(device)\n",
        "\n",
        "      # 모델을 사용하여 입력 데이터를 처리\n",
        "      output = model(data)\n",
        "\n",
        "      # 손실 값 계산 및 누적 (전체 손실을 계산하기 위해 추가)\n",
        "      test_loss += criterion(output, target).item()\n",
        "\n",
        "      # 모델의 출력에서 가장 높은 값을 가지는 클래스 예측\n",
        "      pred = output.argmax(dim=1, keepdim=True)\n",
        "\n",
        "      # 예측값과 실제값을 비교하여 일치하는 경우 정답 개수 증가\n",
        "      correct += pred.eq(target.view_as(pred)).sum()\n",
        "\n",
        "  # 테스트 데이터셋 크기로 나누어 평균 손실 계산\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  # 테스트 결과 출력: 평균 손실과 정확도\n",
        "  print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: '\n",
        "          f'{correct}/{len(test_loader.dataset)} '\n",
        "          f'({100. * correct / len(test_loader.dataset):.0f}%)\\n', end='\\r')"
      ],
      "metadata": {
        "id": "ubD4BpQ4_4A2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epoch = 5 # 학습할 총 에폭 수를 설정\n",
        "\n",
        "# CUDA(GPU)가 사용 가능하면 'cuda' 장치를 사용 그렇지 않으면 'cpu' 사용\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# 모델을 지정된 장치(GPU 또는 CPU)로 이동\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(n_epoch):\n",
        "  train(model, device, train_loader, optimizer, epoch)\n",
        "  test(model, device, test_loader)\n",
        "\n",
        "# 모델의 상태를 저장\n",
        "torch.save(model.state_dict(), 'models/mnist_mpl_model_{}.pth'.format(n_epoch))\n",
        "# 모델의 가중치를 models/mnist_mpl_model_{}.pth 파일에 저장\n",
        "# 파일명에는 학습한 에폭 수를 포함시켜 추적 가능하도록 설정"
      ],
      "metadata": {
        "id": "TFCyPJRJ_3-n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "92649478-6879-4f37-b770-3c0988627437"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.292783\n",
            "Train Epoch: 1 [640/60000 (1%)]\tLoss: 2.294613\n",
            "Train Epoch: 1 [1280/60000 (2%)]\tLoss: 2.289229\n",
            "Train Epoch: 1 [1920/60000 (3%)]\tLoss: 2.288550\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tLoss: 2.283856\n",
            "Train Epoch: 1 [3200/60000 (5%)]\tLoss: 2.264317\n",
            "Train Epoch: 1 [3840/60000 (6%)]\tLoss: 2.266887\n",
            "Train Epoch: 1 [4480/60000 (7%)]\tLoss: 2.243804\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tLoss: 2.233128\n",
            "Train Epoch: 1 [5760/60000 (10%)]\tLoss: 2.199783\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 2.211472\n",
            "Train Epoch: 1 [7040/60000 (12%)]\tLoss: 2.176999\n",
            "Train Epoch: 1 [7680/60000 (13%)]\tLoss: 2.123552\n",
            "Train Epoch: 1 [8320/60000 (14%)]\tLoss: 2.111541\n",
            "Train Epoch: 1 [8960/60000 (15%)]\tLoss: 2.128970\n",
            "Train Epoch: 1 [9600/60000 (16%)]\tLoss: 2.068211\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tLoss: 2.010757\n",
            "Train Epoch: 1 [10880/60000 (18%)]\tLoss: 2.049391\n",
            "Train Epoch: 1 [11520/60000 (19%)]\tLoss: 1.968267\n",
            "Train Epoch: 1 [12160/60000 (20%)]\tLoss: 1.976975\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.967265\n",
            "Train Epoch: 1 [13440/60000 (22%)]\tLoss: 1.944613\n",
            "Train Epoch: 1 [14080/60000 (23%)]\tLoss: 1.946129\n",
            "Train Epoch: 1 [14720/60000 (25%)]\tLoss: 1.940488\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tLoss: 1.904510\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.933699\n",
            "Train Epoch: 1 [16640/60000 (28%)]\tLoss: 2.015651\n",
            "Train Epoch: 1 [17280/60000 (29%)]\tLoss: 1.865034\n",
            "Train Epoch: 1 [17920/60000 (30%)]\tLoss: 1.869030\n",
            "Train Epoch: 1 [18560/60000 (31%)]\tLoss: 1.796055\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 1.906788\n",
            "Train Epoch: 1 [19840/60000 (33%)]\tLoss: 1.797207\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tLoss: 1.842122\n",
            "Train Epoch: 1 [21120/60000 (35%)]\tLoss: 1.795769\n",
            "Train Epoch: 1 [21760/60000 (36%)]\tLoss: 1.805676\n",
            "Train Epoch: 1 [22400/60000 (37%)]\tLoss: 1.775303\n",
            "Train Epoch: 1 [23040/60000 (38%)]\tLoss: 1.821171\n",
            "Train Epoch: 1 [23680/60000 (39%)]\tLoss: 1.902770\n",
            "Train Epoch: 1 [24320/60000 (41%)]\tLoss: 1.768825\n",
            "Train Epoch: 1 [24960/60000 (42%)]\tLoss: 1.783582\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 1.796851\n",
            "Train Epoch: 1 [26240/60000 (44%)]\tLoss: 1.762542\n",
            "Train Epoch: 1 [26880/60000 (45%)]\tLoss: 1.778466\n",
            "Train Epoch: 1 [27520/60000 (46%)]\tLoss: 1.827684\n",
            "Train Epoch: 1 [28160/60000 (47%)]\tLoss: 1.784246\n",
            "Train Epoch: 1 [28800/60000 (48%)]\tLoss: 1.749182\n",
            "Train Epoch: 1 [29440/60000 (49%)]\tLoss: 1.784555\n",
            "Train Epoch: 1 [30080/60000 (50%)]\tLoss: 1.791945\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tLoss: 1.733221\n",
            "Train Epoch: 1 [31360/60000 (52%)]\tLoss: 1.674957\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 1.665308\n",
            "Train Epoch: 1 [32640/60000 (54%)]\tLoss: 1.654021\n",
            "Train Epoch: 1 [33280/60000 (55%)]\tLoss: 1.739612\n",
            "Train Epoch: 1 [33920/60000 (57%)]\tLoss: 1.706291\n",
            "Train Epoch: 1 [34560/60000 (58%)]\tLoss: 1.665502\n",
            "Train Epoch: 1 [35200/60000 (59%)]\tLoss: 1.660432\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tLoss: 1.761935\n",
            "Train Epoch: 1 [36480/60000 (61%)]\tLoss: 1.677548\n",
            "Train Epoch: 1 [37120/60000 (62%)]\tLoss: 1.708918\n",
            "Train Epoch: 1 [37760/60000 (63%)]\tLoss: 1.670126\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 1.688031\n",
            "Train Epoch: 1 [39040/60000 (65%)]\tLoss: 1.636277\n",
            "Train Epoch: 1 [39680/60000 (66%)]\tLoss: 1.679954\n",
            "Train Epoch: 1 [40320/60000 (67%)]\tLoss: 1.706408\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tLoss: 1.735108\n",
            "Train Epoch: 1 [41600/60000 (69%)]\tLoss: 1.734401\n",
            "Train Epoch: 1 [42240/60000 (70%)]\tLoss: 1.729004\n",
            "Train Epoch: 1 [42880/60000 (71%)]\tLoss: 1.659050\n",
            "Train Epoch: 1 [43520/60000 (72%)]\tLoss: 1.754416\n",
            "Train Epoch: 1 [44160/60000 (74%)]\tLoss: 1.726088\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 1.659976\n",
            "Train Epoch: 1 [45440/60000 (76%)]\tLoss: 1.696638\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tLoss: 1.645014\n",
            "Train Epoch: 1 [46720/60000 (78%)]\tLoss: 1.631501\n",
            "Train Epoch: 1 [47360/60000 (79%)]\tLoss: 1.718483\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 1.688871\n",
            "Train Epoch: 1 [48640/60000 (81%)]\tLoss: 1.617742\n",
            "Train Epoch: 1 [49280/60000 (82%)]\tLoss: 1.655054\n",
            "Train Epoch: 1 [49920/60000 (83%)]\tLoss: 1.635558\n",
            "Train Epoch: 1 [50560/60000 (84%)]\tLoss: 1.722860\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 1.661989\n",
            "Train Epoch: 1 [51840/60000 (86%)]\tLoss: 1.633372\n",
            "Train Epoch: 1 [52480/60000 (87%)]\tLoss: 1.668222\n",
            "Train Epoch: 1 [53120/60000 (88%)]\tLoss: 1.648186\n",
            "Train Epoch: 1 [53760/60000 (90%)]\tLoss: 1.752610\n",
            "Train Epoch: 1 [54400/60000 (91%)]\tLoss: 1.748585\n",
            "Train Epoch: 1 [55040/60000 (92%)]\tLoss: 1.743645\n",
            "Train Epoch: 1 [55680/60000 (93%)]\tLoss: 1.745624\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tLoss: 1.692550\n",
            "Train Epoch: 1 [56960/60000 (95%)]\tLoss: 1.717168\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 1.615271\n",
            "Train Epoch: 1 [58240/60000 (97%)]\tLoss: 1.664243\n",
            "Train Epoch: 1 [58880/60000 (98%)]\tLoss: 1.697278\n",
            "Train Epoch: 1 [59520/60000 (99%)]\tLoss: 1.666471\n",
            "\n",
            "Test set: Average loss: 0.0017, Accuracy: 8311/10000 (83%)\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 1.694212\n",
            "Train Epoch: 2 [640/60000 (1%)]\tLoss: 1.674016\n",
            "Train Epoch: 2 [1280/60000 (2%)]\tLoss: 1.643970\n",
            "Train Epoch: 2 [1920/60000 (3%)]\tLoss: 1.664097\n",
            "Train Epoch: 2 [2560/60000 (4%)]\tLoss: 1.635033\n",
            "Train Epoch: 2 [3200/60000 (5%)]\tLoss: 1.609784\n",
            "Train Epoch: 2 [3840/60000 (6%)]\tLoss: 1.670955\n",
            "Train Epoch: 2 [4480/60000 (7%)]\tLoss: 1.615652\n",
            "Train Epoch: 2 [5120/60000 (9%)]\tLoss: 1.699164\n",
            "Train Epoch: 2 [5760/60000 (10%)]\tLoss: 1.657072\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 1.626353\n",
            "Train Epoch: 2 [7040/60000 (12%)]\tLoss: 1.638340\n",
            "Train Epoch: 2 [7680/60000 (13%)]\tLoss: 1.618436\n",
            "Train Epoch: 2 [8320/60000 (14%)]\tLoss: 1.678512\n",
            "Train Epoch: 2 [8960/60000 (15%)]\tLoss: 1.697917\n",
            "Train Epoch: 2 [9600/60000 (16%)]\tLoss: 1.616628\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tLoss: 1.679135\n",
            "Train Epoch: 2 [10880/60000 (18%)]\tLoss: 1.674048\n",
            "Train Epoch: 2 [11520/60000 (19%)]\tLoss: 1.632684\n",
            "Train Epoch: 2 [12160/60000 (20%)]\tLoss: 1.688701\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 1.625782\n",
            "Train Epoch: 2 [13440/60000 (22%)]\tLoss: 1.572572\n",
            "Train Epoch: 2 [14080/60000 (23%)]\tLoss: 1.698444\n",
            "Train Epoch: 2 [14720/60000 (25%)]\tLoss: 1.662400\n",
            "Train Epoch: 2 [15360/60000 (26%)]\tLoss: 1.622942\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 1.635142\n",
            "Train Epoch: 2 [16640/60000 (28%)]\tLoss: 1.672934\n",
            "Train Epoch: 2 [17280/60000 (29%)]\tLoss: 1.596104\n",
            "Train Epoch: 2 [17920/60000 (30%)]\tLoss: 1.587495\n",
            "Train Epoch: 2 [18560/60000 (31%)]\tLoss: 1.618993\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 1.682062\n",
            "Train Epoch: 2 [19840/60000 (33%)]\tLoss: 1.624819\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tLoss: 1.697064\n",
            "Train Epoch: 2 [21120/60000 (35%)]\tLoss: 1.602217\n",
            "Train Epoch: 2 [21760/60000 (36%)]\tLoss: 1.659451\n",
            "Train Epoch: 2 [22400/60000 (37%)]\tLoss: 1.591355\n",
            "Train Epoch: 2 [23040/60000 (38%)]\tLoss: 1.605228\n",
            "Train Epoch: 2 [23680/60000 (39%)]\tLoss: 1.568543\n",
            "Train Epoch: 2 [24320/60000 (41%)]\tLoss: 1.661916\n",
            "Train Epoch: 2 [24960/60000 (42%)]\tLoss: 1.640325\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 1.674196\n",
            "Train Epoch: 2 [26240/60000 (44%)]\tLoss: 1.611101\n",
            "Train Epoch: 2 [26880/60000 (45%)]\tLoss: 1.664489\n",
            "Train Epoch: 2 [27520/60000 (46%)]\tLoss: 1.652653\n",
            "Train Epoch: 2 [28160/60000 (47%)]\tLoss: 1.670127\n",
            "Train Epoch: 2 [28800/60000 (48%)]\tLoss: 1.648903\n",
            "Train Epoch: 2 [29440/60000 (49%)]\tLoss: 1.578211\n",
            "Train Epoch: 2 [30080/60000 (50%)]\tLoss: 1.720951\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tLoss: 1.665456\n",
            "Train Epoch: 2 [31360/60000 (52%)]\tLoss: 1.628409\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 1.585237\n",
            "Train Epoch: 2 [32640/60000 (54%)]\tLoss: 1.607332\n",
            "Train Epoch: 2 [33280/60000 (55%)]\tLoss: 1.652007\n",
            "Train Epoch: 2 [33920/60000 (57%)]\tLoss: 1.628220\n",
            "Train Epoch: 2 [34560/60000 (58%)]\tLoss: 1.586946\n",
            "Train Epoch: 2 [35200/60000 (59%)]\tLoss: 1.708344\n",
            "Train Epoch: 2 [35840/60000 (60%)]\tLoss: 1.649793\n",
            "Train Epoch: 2 [36480/60000 (61%)]\tLoss: 1.605184\n",
            "Train Epoch: 2 [37120/60000 (62%)]\tLoss: 1.622333\n",
            "Train Epoch: 2 [37760/60000 (63%)]\tLoss: 1.702255\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 1.643888\n",
            "Train Epoch: 2 [39040/60000 (65%)]\tLoss: 1.675324\n",
            "Train Epoch: 2 [39680/60000 (66%)]\tLoss: 1.636723\n",
            "Train Epoch: 2 [40320/60000 (67%)]\tLoss: 1.618322\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tLoss: 1.576991\n",
            "Train Epoch: 2 [41600/60000 (69%)]\tLoss: 1.664726\n",
            "Train Epoch: 2 [42240/60000 (70%)]\tLoss: 1.653547\n",
            "Train Epoch: 2 [42880/60000 (71%)]\tLoss: 1.653506\n",
            "Train Epoch: 2 [43520/60000 (72%)]\tLoss: 1.725417\n",
            "Train Epoch: 2 [44160/60000 (74%)]\tLoss: 1.677581\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 1.592271\n",
            "Train Epoch: 2 [45440/60000 (76%)]\tLoss: 1.573132\n",
            "Train Epoch: 2 [46080/60000 (77%)]\tLoss: 1.563979\n",
            "Train Epoch: 2 [46720/60000 (78%)]\tLoss: 1.566600\n",
            "Train Epoch: 2 [47360/60000 (79%)]\tLoss: 1.590315\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 1.621188\n",
            "Train Epoch: 2 [48640/60000 (81%)]\tLoss: 1.615865\n",
            "Train Epoch: 2 [49280/60000 (82%)]\tLoss: 1.599473\n",
            "Train Epoch: 2 [49920/60000 (83%)]\tLoss: 1.641417\n",
            "Train Epoch: 2 [50560/60000 (84%)]\tLoss: 1.582947\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 1.619883\n",
            "Train Epoch: 2 [51840/60000 (86%)]\tLoss: 1.584563\n",
            "Train Epoch: 2 [52480/60000 (87%)]\tLoss: 1.607571\n",
            "Train Epoch: 2 [53120/60000 (88%)]\tLoss: 1.603898\n",
            "Train Epoch: 2 [53760/60000 (90%)]\tLoss: 1.625940\n",
            "Train Epoch: 2 [54400/60000 (91%)]\tLoss: 1.614579\n",
            "Train Epoch: 2 [55040/60000 (92%)]\tLoss: 1.617510\n",
            "Train Epoch: 2 [55680/60000 (93%)]\tLoss: 1.654430\n",
            "Train Epoch: 2 [56320/60000 (94%)]\tLoss: 1.602358\n",
            "Train Epoch: 2 [56960/60000 (95%)]\tLoss: 1.571379\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 1.575473\n",
            "Train Epoch: 2 [58240/60000 (97%)]\tLoss: 1.557164\n",
            "Train Epoch: 2 [58880/60000 (98%)]\tLoss: 1.599744\n",
            "Train Epoch: 2 [59520/60000 (99%)]\tLoss: 1.608638\n",
            "\n",
            "Test set: Average loss: 0.0016, Accuracy: 9023/10000 (90%)\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.580009\n",
            "Train Epoch: 3 [640/60000 (1%)]\tLoss: 1.602155\n",
            "Train Epoch: 3 [1280/60000 (2%)]\tLoss: 1.577102\n",
            "Train Epoch: 3 [1920/60000 (3%)]\tLoss: 1.606212\n",
            "Train Epoch: 3 [2560/60000 (4%)]\tLoss: 1.628641\n",
            "Train Epoch: 3 [3200/60000 (5%)]\tLoss: 1.567151\n",
            "Train Epoch: 3 [3840/60000 (6%)]\tLoss: 1.540853\n",
            "Train Epoch: 3 [4480/60000 (7%)]\tLoss: 1.595611\n",
            "Train Epoch: 3 [5120/60000 (9%)]\tLoss: 1.564657\n",
            "Train Epoch: 3 [5760/60000 (10%)]\tLoss: 1.591949\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 1.565603\n",
            "Train Epoch: 3 [7040/60000 (12%)]\tLoss: 1.633279\n",
            "Train Epoch: 3 [7680/60000 (13%)]\tLoss: 1.592419\n",
            "Train Epoch: 3 [8320/60000 (14%)]\tLoss: 1.617486\n",
            "Train Epoch: 3 [8960/60000 (15%)]\tLoss: 1.614638\n",
            "Train Epoch: 3 [9600/60000 (16%)]\tLoss: 1.586709\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tLoss: 1.553840\n",
            "Train Epoch: 3 [10880/60000 (18%)]\tLoss: 1.592105\n",
            "Train Epoch: 3 [11520/60000 (19%)]\tLoss: 1.648682\n",
            "Train Epoch: 3 [12160/60000 (20%)]\tLoss: 1.570846\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 1.633878\n",
            "Train Epoch: 3 [13440/60000 (22%)]\tLoss: 1.605273\n",
            "Train Epoch: 3 [14080/60000 (23%)]\tLoss: 1.559979\n",
            "Train Epoch: 3 [14720/60000 (25%)]\tLoss: 1.614322\n",
            "Train Epoch: 3 [15360/60000 (26%)]\tLoss: 1.629074\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 1.593941\n",
            "Train Epoch: 3 [16640/60000 (28%)]\tLoss: 1.589323\n",
            "Train Epoch: 3 [17280/60000 (29%)]\tLoss: 1.613146\n",
            "Train Epoch: 3 [17920/60000 (30%)]\tLoss: 1.586599\n",
            "Train Epoch: 3 [18560/60000 (31%)]\tLoss: 1.550116\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 1.567306\n",
            "Train Epoch: 3 [19840/60000 (33%)]\tLoss: 1.533397\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tLoss: 1.578792\n",
            "Train Epoch: 3 [21120/60000 (35%)]\tLoss: 1.637287\n",
            "Train Epoch: 3 [21760/60000 (36%)]\tLoss: 1.623550\n",
            "Train Epoch: 3 [22400/60000 (37%)]\tLoss: 1.565590\n",
            "Train Epoch: 3 [23040/60000 (38%)]\tLoss: 1.621643\n",
            "Train Epoch: 3 [23680/60000 (39%)]\tLoss: 1.597020\n",
            "Train Epoch: 3 [24320/60000 (41%)]\tLoss: 1.516290\n",
            "Train Epoch: 3 [24960/60000 (42%)]\tLoss: 1.559894\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.546298\n",
            "Train Epoch: 3 [26240/60000 (44%)]\tLoss: 1.560917\n",
            "Train Epoch: 3 [26880/60000 (45%)]\tLoss: 1.619426\n",
            "Train Epoch: 3 [27520/60000 (46%)]\tLoss: 1.566343\n",
            "Train Epoch: 3 [28160/60000 (47%)]\tLoss: 1.562572\n",
            "Train Epoch: 3 [28800/60000 (48%)]\tLoss: 1.570685\n",
            "Train Epoch: 3 [29440/60000 (49%)]\tLoss: 1.589661\n",
            "Train Epoch: 3 [30080/60000 (50%)]\tLoss: 1.586817\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tLoss: 1.521876\n",
            "Train Epoch: 3 [31360/60000 (52%)]\tLoss: 1.594157\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 1.554131\n",
            "Train Epoch: 3 [32640/60000 (54%)]\tLoss: 1.588575\n",
            "Train Epoch: 3 [33280/60000 (55%)]\tLoss: 1.640664\n",
            "Train Epoch: 3 [33920/60000 (57%)]\tLoss: 1.507514\n",
            "Train Epoch: 3 [34560/60000 (58%)]\tLoss: 1.557649\n",
            "Train Epoch: 3 [35200/60000 (59%)]\tLoss: 1.565380\n",
            "Train Epoch: 3 [35840/60000 (60%)]\tLoss: 1.594414\n",
            "Train Epoch: 3 [36480/60000 (61%)]\tLoss: 1.555299\n",
            "Train Epoch: 3 [37120/60000 (62%)]\tLoss: 1.569077\n",
            "Train Epoch: 3 [37760/60000 (63%)]\tLoss: 1.544679\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 1.541150\n",
            "Train Epoch: 3 [39040/60000 (65%)]\tLoss: 1.607832\n",
            "Train Epoch: 3 [39680/60000 (66%)]\tLoss: 1.559661\n",
            "Train Epoch: 3 [40320/60000 (67%)]\tLoss: 1.555449\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tLoss: 1.599891\n",
            "Train Epoch: 3 [41600/60000 (69%)]\tLoss: 1.553880\n",
            "Train Epoch: 3 [42240/60000 (70%)]\tLoss: 1.584879\n",
            "Train Epoch: 3 [42880/60000 (71%)]\tLoss: 1.606333\n",
            "Train Epoch: 3 [43520/60000 (72%)]\tLoss: 1.600311\n",
            "Train Epoch: 3 [44160/60000 (74%)]\tLoss: 1.576897\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 1.589590\n",
            "Train Epoch: 3 [45440/60000 (76%)]\tLoss: 1.570949\n",
            "Train Epoch: 3 [46080/60000 (77%)]\tLoss: 1.588499\n",
            "Train Epoch: 3 [46720/60000 (78%)]\tLoss: 1.596533\n",
            "Train Epoch: 3 [47360/60000 (79%)]\tLoss: 1.555314\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 1.591438\n",
            "Train Epoch: 3 [48640/60000 (81%)]\tLoss: 1.522685\n",
            "Train Epoch: 3 [49280/60000 (82%)]\tLoss: 1.563761\n",
            "Train Epoch: 3 [49920/60000 (83%)]\tLoss: 1.552710\n",
            "Train Epoch: 3 [50560/60000 (84%)]\tLoss: 1.532207\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.553948\n",
            "Train Epoch: 3 [51840/60000 (86%)]\tLoss: 1.556673\n",
            "Train Epoch: 3 [52480/60000 (87%)]\tLoss: 1.570806\n",
            "Train Epoch: 3 [53120/60000 (88%)]\tLoss: 1.547636\n",
            "Train Epoch: 3 [53760/60000 (90%)]\tLoss: 1.577325\n",
            "Train Epoch: 3 [54400/60000 (91%)]\tLoss: 1.587104\n",
            "Train Epoch: 3 [55040/60000 (92%)]\tLoss: 1.542457\n",
            "Train Epoch: 3 [55680/60000 (93%)]\tLoss: 1.580919\n",
            "Train Epoch: 3 [56320/60000 (94%)]\tLoss: 1.620748\n",
            "Train Epoch: 3 [56960/60000 (95%)]\tLoss: 1.563506\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 1.543934\n",
            "Train Epoch: 3 [58240/60000 (97%)]\tLoss: 1.534426\n",
            "Train Epoch: 3 [58880/60000 (98%)]\tLoss: 1.533162\n",
            "Train Epoch: 3 [59520/60000 (99%)]\tLoss: 1.548694\n",
            "\n",
            "Test set: Average loss: 0.0016, Accuracy: 9163/10000 (92%)\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.579368\n",
            "Train Epoch: 4 [640/60000 (1%)]\tLoss: 1.542377\n",
            "Train Epoch: 4 [1280/60000 (2%)]\tLoss: 1.521596\n",
            "Train Epoch: 4 [1920/60000 (3%)]\tLoss: 1.596339\n",
            "Train Epoch: 4 [2560/60000 (4%)]\tLoss: 1.541800\n",
            "Train Epoch: 4 [3200/60000 (5%)]\tLoss: 1.599497\n",
            "Train Epoch: 4 [3840/60000 (6%)]\tLoss: 1.615326\n",
            "Train Epoch: 4 [4480/60000 (7%)]\tLoss: 1.544784\n",
            "Train Epoch: 4 [5120/60000 (9%)]\tLoss: 1.558865\n",
            "Train Epoch: 4 [5760/60000 (10%)]\tLoss: 1.571242\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 1.526967\n",
            "Train Epoch: 4 [7040/60000 (12%)]\tLoss: 1.524352\n",
            "Train Epoch: 4 [7680/60000 (13%)]\tLoss: 1.572595\n",
            "Train Epoch: 4 [8320/60000 (14%)]\tLoss: 1.590099\n",
            "Train Epoch: 4 [8960/60000 (15%)]\tLoss: 1.605986\n",
            "Train Epoch: 4 [9600/60000 (16%)]\tLoss: 1.549562\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tLoss: 1.601389\n",
            "Train Epoch: 4 [10880/60000 (18%)]\tLoss: 1.569060\n",
            "Train Epoch: 4 [11520/60000 (19%)]\tLoss: 1.504560\n",
            "Train Epoch: 4 [12160/60000 (20%)]\tLoss: 1.558084\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.532152\n",
            "Train Epoch: 4 [13440/60000 (22%)]\tLoss: 1.551723\n",
            "Train Epoch: 4 [14080/60000 (23%)]\tLoss: 1.540375\n",
            "Train Epoch: 4 [14720/60000 (25%)]\tLoss: 1.532067\n",
            "Train Epoch: 4 [15360/60000 (26%)]\tLoss: 1.549913\n",
            "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 1.545669\n",
            "Train Epoch: 4 [16640/60000 (28%)]\tLoss: 1.589064\n",
            "Train Epoch: 4 [17280/60000 (29%)]\tLoss: 1.595617\n",
            "Train Epoch: 4 [17920/60000 (30%)]\tLoss: 1.571374\n",
            "Train Epoch: 4 [18560/60000 (31%)]\tLoss: 1.625957\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 1.584890\n",
            "Train Epoch: 4 [19840/60000 (33%)]\tLoss: 1.595386\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tLoss: 1.497697\n",
            "Train Epoch: 4 [21120/60000 (35%)]\tLoss: 1.626141\n",
            "Train Epoch: 4 [21760/60000 (36%)]\tLoss: 1.535966\n",
            "Train Epoch: 4 [22400/60000 (37%)]\tLoss: 1.592840\n",
            "Train Epoch: 4 [23040/60000 (38%)]\tLoss: 1.581373\n",
            "Train Epoch: 4 [23680/60000 (39%)]\tLoss: 1.567602\n",
            "Train Epoch: 4 [24320/60000 (41%)]\tLoss: 1.550726\n",
            "Train Epoch: 4 [24960/60000 (42%)]\tLoss: 1.573693\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.551048\n",
            "Train Epoch: 4 [26240/60000 (44%)]\tLoss: 1.535939\n",
            "Train Epoch: 4 [26880/60000 (45%)]\tLoss: 1.572452\n",
            "Train Epoch: 4 [27520/60000 (46%)]\tLoss: 1.556919\n",
            "Train Epoch: 4 [28160/60000 (47%)]\tLoss: 1.538376\n",
            "Train Epoch: 4 [28800/60000 (48%)]\tLoss: 1.602405\n",
            "Train Epoch: 4 [29440/60000 (49%)]\tLoss: 1.560684\n",
            "Train Epoch: 4 [30080/60000 (50%)]\tLoss: 1.588320\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tLoss: 1.585992\n",
            "Train Epoch: 4 [31360/60000 (52%)]\tLoss: 1.536364\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 1.540799\n",
            "Train Epoch: 4 [32640/60000 (54%)]\tLoss: 1.609805\n",
            "Train Epoch: 4 [33280/60000 (55%)]\tLoss: 1.514485\n",
            "Train Epoch: 4 [33920/60000 (57%)]\tLoss: 1.611117\n",
            "Train Epoch: 4 [34560/60000 (58%)]\tLoss: 1.576877\n",
            "Train Epoch: 4 [35200/60000 (59%)]\tLoss: 1.560224\n",
            "Train Epoch: 4 [35840/60000 (60%)]\tLoss: 1.544485\n",
            "Train Epoch: 4 [36480/60000 (61%)]\tLoss: 1.536520\n",
            "Train Epoch: 4 [37120/60000 (62%)]\tLoss: 1.529545\n",
            "Train Epoch: 4 [37760/60000 (63%)]\tLoss: 1.515942\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.575995\n",
            "Train Epoch: 4 [39040/60000 (65%)]\tLoss: 1.526867\n",
            "Train Epoch: 4 [39680/60000 (66%)]\tLoss: 1.587092\n",
            "Train Epoch: 4 [40320/60000 (67%)]\tLoss: 1.576976\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tLoss: 1.580978\n",
            "Train Epoch: 4 [41600/60000 (69%)]\tLoss: 1.577645\n",
            "Train Epoch: 4 [42240/60000 (70%)]\tLoss: 1.537364\n",
            "Train Epoch: 4 [42880/60000 (71%)]\tLoss: 1.541042\n",
            "Train Epoch: 4 [43520/60000 (72%)]\tLoss: 1.540665\n",
            "Train Epoch: 4 [44160/60000 (74%)]\tLoss: 1.564932\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 1.565071\n",
            "Train Epoch: 4 [45440/60000 (76%)]\tLoss: 1.526565\n",
            "Train Epoch: 4 [46080/60000 (77%)]\tLoss: 1.567029\n",
            "Train Epoch: 4 [46720/60000 (78%)]\tLoss: 1.575650\n",
            "Train Epoch: 4 [47360/60000 (79%)]\tLoss: 1.535658\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 1.500529\n",
            "Train Epoch: 4 [48640/60000 (81%)]\tLoss: 1.523457\n",
            "Train Epoch: 4 [49280/60000 (82%)]\tLoss: 1.520292\n",
            "Train Epoch: 4 [49920/60000 (83%)]\tLoss: 1.511986\n",
            "Train Epoch: 4 [50560/60000 (84%)]\tLoss: 1.529469\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.604673\n",
            "Train Epoch: 4 [51840/60000 (86%)]\tLoss: 1.535167\n",
            "Train Epoch: 4 [52480/60000 (87%)]\tLoss: 1.548310\n",
            "Train Epoch: 4 [53120/60000 (88%)]\tLoss: 1.615444\n",
            "Train Epoch: 4 [53760/60000 (90%)]\tLoss: 1.548622\n",
            "Train Epoch: 4 [54400/60000 (91%)]\tLoss: 1.575484\n",
            "Train Epoch: 4 [55040/60000 (92%)]\tLoss: 1.526528\n",
            "Train Epoch: 4 [55680/60000 (93%)]\tLoss: 1.618307\n",
            "Train Epoch: 4 [56320/60000 (94%)]\tLoss: 1.546379\n",
            "Train Epoch: 4 [56960/60000 (95%)]\tLoss: 1.550261\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 1.495146\n",
            "Train Epoch: 4 [58240/60000 (97%)]\tLoss: 1.589736\n",
            "Train Epoch: 4 [58880/60000 (98%)]\tLoss: 1.517526\n",
            "Train Epoch: 4 [59520/60000 (99%)]\tLoss: 1.566124\n",
            "\n",
            "Test set: Average loss: 0.0016, Accuracy: 9231/10000 (92%)\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.565742\n",
            "Train Epoch: 5 [640/60000 (1%)]\tLoss: 1.600515\n",
            "Train Epoch: 5 [1280/60000 (2%)]\tLoss: 1.573544\n",
            "Train Epoch: 5 [1920/60000 (3%)]\tLoss: 1.560563\n",
            "Train Epoch: 5 [2560/60000 (4%)]\tLoss: 1.610635\n",
            "Train Epoch: 5 [3200/60000 (5%)]\tLoss: 1.538612\n",
            "Train Epoch: 5 [3840/60000 (6%)]\tLoss: 1.539756\n",
            "Train Epoch: 5 [4480/60000 (7%)]\tLoss: 1.567865\n",
            "Train Epoch: 5 [5120/60000 (9%)]\tLoss: 1.541763\n",
            "Train Epoch: 5 [5760/60000 (10%)]\tLoss: 1.488790\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 1.590901\n",
            "Train Epoch: 5 [7040/60000 (12%)]\tLoss: 1.550786\n",
            "Train Epoch: 5 [7680/60000 (13%)]\tLoss: 1.548398\n",
            "Train Epoch: 5 [8320/60000 (14%)]\tLoss: 1.521728\n",
            "Train Epoch: 5 [8960/60000 (15%)]\tLoss: 1.597649\n",
            "Train Epoch: 5 [9600/60000 (16%)]\tLoss: 1.535873\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tLoss: 1.589298\n",
            "Train Epoch: 5 [10880/60000 (18%)]\tLoss: 1.524463\n",
            "Train Epoch: 5 [11520/60000 (19%)]\tLoss: 1.549865\n",
            "Train Epoch: 5 [12160/60000 (20%)]\tLoss: 1.549285\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.543823\n",
            "Train Epoch: 5 [13440/60000 (22%)]\tLoss: 1.602226\n",
            "Train Epoch: 5 [14080/60000 (23%)]\tLoss: 1.586143\n",
            "Train Epoch: 5 [14720/60000 (25%)]\tLoss: 1.547747\n",
            "Train Epoch: 5 [15360/60000 (26%)]\tLoss: 1.589051\n",
            "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 1.547435\n",
            "Train Epoch: 5 [16640/60000 (28%)]\tLoss: 1.538612\n",
            "Train Epoch: 5 [17280/60000 (29%)]\tLoss: 1.572421\n",
            "Train Epoch: 5 [17920/60000 (30%)]\tLoss: 1.509074\n",
            "Train Epoch: 5 [18560/60000 (31%)]\tLoss: 1.546176\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 1.587892\n",
            "Train Epoch: 5 [19840/60000 (33%)]\tLoss: 1.588624\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tLoss: 1.561580\n",
            "Train Epoch: 5 [21120/60000 (35%)]\tLoss: 1.534509\n",
            "Train Epoch: 5 [21760/60000 (36%)]\tLoss: 1.586329\n",
            "Train Epoch: 5 [22400/60000 (37%)]\tLoss: 1.584486\n",
            "Train Epoch: 5 [23040/60000 (38%)]\tLoss: 1.561113\n",
            "Train Epoch: 5 [23680/60000 (39%)]\tLoss: 1.538880\n",
            "Train Epoch: 5 [24320/60000 (41%)]\tLoss: 1.597878\n",
            "Train Epoch: 5 [24960/60000 (42%)]\tLoss: 1.563389\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 1.539352\n",
            "Train Epoch: 5 [26240/60000 (44%)]\tLoss: 1.546347\n",
            "Train Epoch: 5 [26880/60000 (45%)]\tLoss: 1.546340\n",
            "Train Epoch: 5 [27520/60000 (46%)]\tLoss: 1.564165\n",
            "Train Epoch: 5 [28160/60000 (47%)]\tLoss: 1.530225\n",
            "Train Epoch: 5 [28800/60000 (48%)]\tLoss: 1.560541\n",
            "Train Epoch: 5 [29440/60000 (49%)]\tLoss: 1.572675\n",
            "Train Epoch: 5 [30080/60000 (50%)]\tLoss: 1.531328\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tLoss: 1.545795\n",
            "Train Epoch: 5 [31360/60000 (52%)]\tLoss: 1.490006\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 1.617961\n",
            "Train Epoch: 5 [32640/60000 (54%)]\tLoss: 1.618121\n",
            "Train Epoch: 5 [33280/60000 (55%)]\tLoss: 1.553622\n",
            "Train Epoch: 5 [33920/60000 (57%)]\tLoss: 1.608059\n",
            "Train Epoch: 5 [34560/60000 (58%)]\tLoss: 1.579385\n",
            "Train Epoch: 5 [35200/60000 (59%)]\tLoss: 1.512288\n",
            "Train Epoch: 5 [35840/60000 (60%)]\tLoss: 1.576228\n",
            "Train Epoch: 5 [36480/60000 (61%)]\tLoss: 1.549507\n",
            "Train Epoch: 5 [37120/60000 (62%)]\tLoss: 1.621256\n",
            "Train Epoch: 5 [37760/60000 (63%)]\tLoss: 1.535236\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.538157\n",
            "Train Epoch: 5 [39040/60000 (65%)]\tLoss: 1.538548\n",
            "Train Epoch: 5 [39680/60000 (66%)]\tLoss: 1.548275\n",
            "Train Epoch: 5 [40320/60000 (67%)]\tLoss: 1.603444\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tLoss: 1.555348\n",
            "Train Epoch: 5 [41600/60000 (69%)]\tLoss: 1.544446\n",
            "Train Epoch: 5 [42240/60000 (70%)]\tLoss: 1.555943\n",
            "Train Epoch: 5 [42880/60000 (71%)]\tLoss: 1.532433\n",
            "Train Epoch: 5 [43520/60000 (72%)]\tLoss: 1.591491\n",
            "Train Epoch: 5 [44160/60000 (74%)]\tLoss: 1.513090\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 1.613071\n",
            "Train Epoch: 5 [45440/60000 (76%)]\tLoss: 1.529313\n",
            "Train Epoch: 5 [46080/60000 (77%)]\tLoss: 1.594236\n",
            "Train Epoch: 5 [46720/60000 (78%)]\tLoss: 1.570443\n",
            "Train Epoch: 5 [47360/60000 (79%)]\tLoss: 1.556578\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 1.576510\n",
            "Train Epoch: 5 [48640/60000 (81%)]\tLoss: 1.548093\n",
            "Train Epoch: 5 [49280/60000 (82%)]\tLoss: 1.558161\n",
            "Train Epoch: 5 [49920/60000 (83%)]\tLoss: 1.566581\n",
            "Train Epoch: 5 [50560/60000 (84%)]\tLoss: 1.535333\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.572440\n",
            "Train Epoch: 5 [51840/60000 (86%)]\tLoss: 1.557651\n",
            "Train Epoch: 5 [52480/60000 (87%)]\tLoss: 1.519645\n",
            "Train Epoch: 5 [53120/60000 (88%)]\tLoss: 1.546872\n",
            "Train Epoch: 5 [53760/60000 (90%)]\tLoss: 1.492277\n",
            "Train Epoch: 5 [54400/60000 (91%)]\tLoss: 1.605526\n",
            "Train Epoch: 5 [55040/60000 (92%)]\tLoss: 1.551443\n",
            "Train Epoch: 5 [55680/60000 (93%)]\tLoss: 1.537659\n",
            "Train Epoch: 5 [56320/60000 (94%)]\tLoss: 1.582460\n",
            "Train Epoch: 5 [56960/60000 (95%)]\tLoss: 1.560004\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 1.560406\n",
            "Train Epoch: 5 [58240/60000 (97%)]\tLoss: 1.564126\n",
            "Train Epoch: 5 [58880/60000 (98%)]\tLoss: 1.560720\n",
            "Train Epoch: 5 [59520/60000 (99%)]\tLoss: 1.526426\n",
            "\n",
            "Test set: Average loss: 0.0015, Accuracy: 9273/10000 (93%)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Parent directory models does not exist.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-c08fcf0d1dee>\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 모델의 상태를 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'models/mnist_mpl_model_{}.pth'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;31m# 모델의 가중치를 models/mnist_mpl_model_{}.pth 파일에 저장\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# 파일명에는 학습한 에폭 수를 포함시켜 추적 가능하도록 설정\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001b[0m\n\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m             _save(\n\u001b[1;32m    851\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    714\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m         \u001b[0mcontainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open_zipfile_writer_buffer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    685\u001b[0m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_stream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 687\u001b[0;31m             \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPyTorchFileWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Parent directory models does not exist."
          ]
        }
      ]
    }
  ]
}